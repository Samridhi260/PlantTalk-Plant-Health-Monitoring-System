import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score
import joblib

# Load the dataset
df = pd.read_csv("tomato_with_mood_interleaved.csv")

# Ensure numeric conversion of sensor columns
columns = ['Temperature ', 'Humidity', 'Soil moisture', 'Solar Radiation']
df[columns] = df[columns].apply(pd.to_numeric, errors='coerce')

# Add real-world-like noise
np.random.seed(42)
df_noisy = df.copy()
df_noisy['Temperature '] += np.random.normal(0, 1, size=len(df))
df_noisy['Humidity'] += np.random.normal(0, 2, size=len(df))
df_noisy['Soil moisture'] += np.random.normal(0, 10, size=len(df))
df_noisy['Solar Radiation'] += np.random.normal(0, 20, size=len(df))

# Clip negative values
df_noisy[columns] = df_noisy[columns].clip(lower=0)

# Encode target labels
le = LabelEncoder()
df_noisy['Mood_Label'] = le.fit_transform(df_noisy['Plant Mood'])

# Split data
X = df_noisy[columns]
y = df_noisy['Mood_Label']
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Train Decision Tree with overfitting control
model = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10, random_state=42)
model.fit(X_train, y_train)

# Evaluate model
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Report:\n", classification_report(y_test, y_pred, target_names=le.classes_))
print("Tree Rules:\n", export_text(model, feature_names=columns))

# Save model and label encoder
joblib.dump(model, "plant_mood_model_dt.pkl")
joblib.dump(le, "plant_mood_label_encoder.pkl")
print("Model and encoder saved.")
